{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from torchvision import transforms\n",
    "\n",
    "from dsd import DSDTraining\n",
    "from utils import set_all_seed\n",
    "\n",
    "# Config\n",
    "data_path = \"data\"\n",
    "image_size = (224, 224)\n",
    "batch_size = 16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I/ Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FER2013(Dataset):\n",
    "    def __init__(self, stage):\n",
    "        self._stage = stage\n",
    "        self._image_size = image_size\n",
    "        self._data = pd.read_csv(os.path.join(data_path, \"{}.csv\".format(stage)))\n",
    "        self._pixels = self._data[\"pixels\"].tolist()\n",
    "        self._emotions = pd.get_dummies(self._data[\"emotion\"])\n",
    "        self._train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[0.1, 0.1, 0.1]),\n",
    "            ]\n",
    "        )\n",
    "        self._val_test_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0, 0, 0], std=[0.1, 0.1, 0.1]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._pixels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pixels = self._pixels[idx]\n",
    "        pixels = list(map(int, pixels.split(\" \")))\n",
    "        image = np.asarray(pixels).reshape(48, 48)\n",
    "        image = image.astype(np.uint8)\n",
    "        image = cv2.resize(image, self._image_size)\n",
    "        image = np.dstack([image] * 3)\n",
    "\n",
    "        if self._stage == \"train\":\n",
    "            image = self._train_transform(image)\n",
    "        else:\n",
    "            image = self._val_test_transform(image)\n",
    "\n",
    "        target = self._emotions.iloc[idx].idxmax()\n",
    "        return image, target\n",
    "\n",
    "\n",
    "train_set = FER2013(stage=\"train\")\n",
    "val_set = FER2013(stage=\"val\")\n",
    "test_set = FER2013(stage=\"test\")\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II/ Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_16(nn.Module):\n",
    "    \"\"\"\n",
    "    Main Class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Constructor\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.block_size = [2, 2, 3, 3, 3]\n",
    "        self.conv_1_1 = nn.Conv2d(3, 64, 3, stride=1, padding=1)\n",
    "        self.conv_1_2 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
    "        self.conv_2_1 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.conv_2_2 = nn.Conv2d(128, 128, 3, stride=1, padding=1)\n",
    "        self.conv_3_1 = nn.Conv2d(128, 256, 3, stride=1, padding=1)\n",
    "        self.conv_3_2 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "        self.conv_3_3 = nn.Conv2d(256, 256, 3, stride=1, padding=1)\n",
    "        self.conv_4_1 = nn.Conv2d(256, 512, 3, stride=1, padding=1)\n",
    "        self.conv_4_2 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.conv_4_3 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.conv_5_1 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.conv_5_2 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.conv_5_3 = nn.Conv2d(512, 512, 3, stride=1, padding=1)\n",
    "        self.fc6 = nn.Linear(512 * 7 * 7, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, 2622)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Pytorch forward\n",
    "        Args:\n",
    "            x: input image (224x224)\n",
    "        Returns: class logits\n",
    "        \"\"\"\n",
    "        x = F.relu(self.conv_1_1(x))\n",
    "        x = F.relu(self.conv_1_2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv_2_1(x))\n",
    "        x = F.relu(self.conv_2_2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv_3_1(x))\n",
    "        x = F.relu(self.conv_3_2(x))\n",
    "        x = F.relu(self.conv_3_3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv_4_1(x))\n",
    "        x = F.relu(self.conv_4_2(x))\n",
    "        x = F.relu(self.conv_4_3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv_5_1(x))\n",
    "        x = F.relu(self.conv_5_2(x))\n",
    "        x = F.relu(self.conv_5_3(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = F.dropout(x, 0.7, self.training)\n",
    "        x = F.relu(self.fc7(x))\n",
    "        # x = F.dropout(x, 0.5, self.training) # Don't know if they use this dropout layer\n",
    "        return self.fc8(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG_16()\n",
    "model.load_state_dict(torch.load(\"pretrained/VGG_FACE_converted.pth\"))\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "model.fc6.weight.requires_grad = True\n",
    "model.fc7.weight.requires_grad = True\n",
    "# biases? Now they are True and they are all 0\n",
    "\n",
    "model.fc8 = nn.Linear(4096, 7)\n",
    "model.fc8.weight.data.normal_(mean=0.0, std=0.1)\n",
    "model.fc8.bias.data.zero_()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "dsd_model = DSDTraining(model, sparsity=0.6)\n",
    "summary(dsd_model, (3, 224, 224))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III/ Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(dsd_model.parameters(), lr=0.0001, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dsd(\n",
    "    dsd_model,\n",
    "    EPOCH_DENSE1,\n",
    "    EPOCH_SPARSE1,\n",
    "    EPOCH_DENSE2,\n",
    "    EPOCH_SPARSE2,\n",
    "    EPOCH_DENSE3,\n",
    "    NB_TRAIN_EXAMPLES,\n",
    "    NB_VAL_EXAMPLES,\n",
    "):\n",
    "\n",
    "    EPOCHS = EPOCH_DENSE1 + EPOCH_SPARSE1 + EPOCH_DENSE2 + EPOCH_SPARSE2 + EPOCH_DENSE3\n",
    "    train_costs, val_costs = [], []\n",
    "    val_loss_dec_counter = 0\n",
    "    prev_val_loss = 0\n",
    "    current_lr = 0.0001\n",
    "\n",
    "    # Training phase.\n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        print(\n",
    "            f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Train Acc':^12} | {'Val Loss':^10} | {'Val Acc':^10} | {'Elapsed':^9}\"\n",
    "        )\n",
    "        print(\"-\" * 85)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # DSD\n",
    "        if (\n",
    "            epoch >= EPOCH_DENSE1\n",
    "            and epoch < EPOCH_DENSE1 + EPOCH_SPARSE1\n",
    "            or epoch >= EPOCH_DENSE1 + EPOCH_SPARSE1 + EPOCH_DENSE2\n",
    "            and epoch < EPOCH_DENSE1 + EPOCH_SPARSE1 + EPOCH_DENSE2 + EPOCH_SPARSE2\n",
    "        ):\n",
    "            dsd_model.train_on_sparse = True\n",
    "        else:\n",
    "            dsd_model.train_on_sparse = False\n",
    "\n",
    "        if dsd_model.train_on_sparse:\n",
    "            dsd_model.update_masks()\n",
    "\n",
    "        # ------------------------------------------------\n",
    "        #                 TRAINING\n",
    "        # ------------------------------------------------\n",
    "\n",
    "        train_loss, correct_train = 0, 0\n",
    "        batch_loss, correct_batch, batch_counts = 0, 0, 0\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            dsd_model.train().cuda()\n",
    "\n",
    "        for step, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "            # Load data to GPU.\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass.\n",
    "            prediction = dsd_model(inputs)\n",
    "\n",
    "            # Compute the loss.\n",
    "            loss = criterion(prediction, labels)\n",
    "\n",
    "            # Backward pass.\n",
    "            loss.backward()\n",
    "\n",
    "            # Sparse-phase\n",
    "            if dsd_model.train_on_sparse:\n",
    "                for (w, b), (mask_w, mask_b) in zip(dsd_model.layers, dsd_model.masks):\n",
    "                    # Values\n",
    "                    w.data[mask_w] = 0\n",
    "                    b.data[mask_b] = 0\n",
    "                    # Grad\n",
    "                    w.grad.data[mask_w] = 0\n",
    "                    b.grad.data[mask_b] = 0\n",
    "\n",
    "            # Optimize.\n",
    "            optimizer.step()\n",
    "\n",
    "            # Compute training accuracy.\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "            correct_batch += (predicted == labels).sum().item()\n",
    "\n",
    "            # Compute batch loss.\n",
    "            batch_loss += loss.data.item() * inputs.shape[0]\n",
    "            train_loss += loss.data.item() * inputs.shape[0]\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 100 == 0 and step != 0) or (step == len(train_loader) - 1):\n",
    "\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                print(\n",
    "                    f\"{epoch + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {correct_batch / batch_counts:^12.6f} | {'-':^10} | {'-':^10} |  {time_elapsed:^9.2f}\"\n",
    "                )\n",
    "                batch_loss, correct_batch, batch_counts = 0, 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "            batch_counts += inputs.shape[0]\n",
    "\n",
    "        train_loss /= NB_TRAIN_EXAMPLES\n",
    "        train_costs.append(train_loss)\n",
    "        train_acc = correct_train / NB_TRAIN_EXAMPLES\n",
    "\n",
    "        print(\"-\" * 85)\n",
    "\n",
    "        # ------------------------------------------------\n",
    "        #                 VALIDATION\n",
    "        # ------------------------------------------------\n",
    "\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "\n",
    "        if device == \"cuda\":\n",
    "            dsd_model.eval().cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                # Load data to GPU.\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass.\n",
    "                prediction = dsd_model(inputs)\n",
    "\n",
    "                # Compute the loss.\n",
    "                loss = criterion(prediction, labels)\n",
    "\n",
    "                # Compute training accuracy.\n",
    "                _, predicted = torch.max(prediction.data, 1)\n",
    "                correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "                # Compute batch loss.\n",
    "                val_loss += loss.data.item() * inputs.shape[0]\n",
    "\n",
    "            val_loss /= NB_VAL_EXAMPLES\n",
    "            val_costs.append(val_loss)\n",
    "            val_acc = correct_val / NB_VAL_EXAMPLES\n",
    "\n",
    "        time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "        # checking and updating lr if needed\n",
    "        if val_loss < prev_val_loss:\n",
    "            val_loss_dec_counter = val_loss_dec_counter + 1\n",
    "        else:\n",
    "            val_loss_dec_counter = 0\n",
    "        if val_loss_dec_counter == 10:\n",
    "            for g in optimizer.param_groups:\n",
    "                g[\"lr\"] = current_lr / 10\n",
    "            current_lr = current_lr / 10\n",
    "            print(f\"New learning rate: {current_lr}\")\n",
    "            val_loss_dec_counter = 0\n",
    "        prev_val_loss = val_loss\n",
    "\n",
    "        info = \"[Epoch {}/{}]: train_on_sparse = {} | train-loss = {:0.6f} | train-acc = {:0.6f} | val-loss = {:0.6f} | val-acc = {:0.6f} | time_elapsed = {:0.2f}\"\n",
    "        print(\n",
    "            info.format(\n",
    "                epoch + 1,\n",
    "                EPOCHS,\n",
    "                dsd_model.train_on_sparse,\n",
    "                train_loss,\n",
    "                train_acc,\n",
    "                val_loss,\n",
    "                val_acc,\n",
    "                time_elapsed,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # # Save plots.\n",
    "        # if (epoch + 1 == EPOCH_DENSE1):\n",
    "        #     plot_wb(dsd_model, \"dense1.png\")\n",
    "        # elif (epoch + 1 == EPOCH_DENSE1 + EPOCH_SPARSE):\n",
    "        #     plot_wb(dsd_model, \"sparse.png\")\n",
    "        # elif (epoch + 1 == EPOCHS):\n",
    "        #     plot_wb(dsd_model, \"dense2.png\")\n",
    "\n",
    "    return train_costs, val_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH_DENSE1 = 200\n",
    "EPOCH_SPARSE1 = 50\n",
    "EPOCH_DENSE2 = 50\n",
    "EPOCH_SPARSE2 = 50\n",
    "EPOCH_DENSE3 = 50\n",
    "NB_TRAIN_EXAMPLES = len(train_loader.dataset)\n",
    "NB_VAL_EXAMPLES = len(val_loader.dataset)\n",
    "\n",
    "set_all_seed(42)\n",
    "train_costs, val_costs = train_dsd(\n",
    "    dsd_model,\n",
    "    EPOCH_DENSE1,\n",
    "    EPOCH_SPARSE1,\n",
    "    EPOCH_DENSE2,\n",
    "    EPOCH_SPARSE2,\n",
    "    EPOCH_DENSE3,\n",
    "    NB_TRAIN_EXAMPLES,\n",
    "    NB_VAL_EXAMPLES,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5758b30e3178d5a7bf625d8b1cc87a97431898af7ee144147b8431fa7285606"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
